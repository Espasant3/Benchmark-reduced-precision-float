## Problemas Encontrados

1. La generación directa de datos aleatorios para tipos de punto flotante de media precisión resulta en valores NaN. Es necesario utilizar una variable intermedia y luego realizar un cast para generar los datos correctamente.
2. Mi procesador no soporta instrucciones AVX512FP16 de manera nativa.
3. En el código del algoritmo de PCA, como trabajamos con cblas y lapacke, las versiones que emplean float de media precision (y brain float) no son completamente igual a la versión que emplea float de 32 bits porque no se hacen exactamente las mismas operaciones. 
 - La función `cblas_sgemm` tiene una función equivalente llamada `cblas_hgemm`, definida en la libería armpl.h, que solo se puede utilizar en arquitecturas ARM y será utilizada cuando se trabaje en esta arquitectura (los programas que usen los tipos de dato _Float16 y __bf16 hará una conversión intermedia para poder utilizar esta función).
 - La función `LAPACKE_ssyev` por el contrario no dispone a día de hoy de ningún equivalente que trabaje con float de media precisión (o con brain float) por lo que todos los programas que no trabajan con el tipo de dato float tienen que hacer una conversión para poder trabajar con esta función.
4. No es posible solucionar el problema anterior realizando un cast al tipo de dato requerido por las funciones en la propia llamada a la función puesto que estas funciones requieren que la memoria esté alineada para funcionar correctamente.
5. Debido al tiempo de ejecución requerido por los programas que implementan el algoritmo DCT con valores de gran magnitud, se ha reducido el tamaño de la muestra de valores de n hasta 1742848, que corresponde al valor que satura la memoria caché L3 del procesador Intel utilizado en este estudio.
6. La implementación total del `LAPACKE_ssyev` a _Float16 (y también a __fp16 y a __bf16) es posible, pero debido a la pérdida de precisión que se deriva del cambio de tipos de datos ocasiona malfuncionamiento a lo largo de los algoritmos originales (que no se adaptan ya que el proceso consiste en una conversión simple a uso de _Float16 en las operaciones) tales como propagación excesiva de los errores de redondeo (por ejemplo algoritmo QR) o una tolerancia insuficiente para la convergencia de los algoritmos. En resumen, los errores acumulados y la tolerancia insuficiente para convergencia ocasionan que los vectores y valores propios obtenidos no sea precisos.
7. Para abordar el problema anterior se podrían implementar internamente en float algunas de las funciones clave del programa, para intentar reducir el error acumulado y poder tener unos resultados más fieles a la realidad.
8. Las macros de gcc `__FLT16_MAX_10_EXP__`, `__FLT16_MIN_10_EXP__`, `__BFLT16_MAX_10_EXP__` y `__BFLT16_MIN_10_EXP__` contenían unos valores que no se correspondían con los valores reales (estándar IEEE 754), por ese motivo han sido declarados manualmente.